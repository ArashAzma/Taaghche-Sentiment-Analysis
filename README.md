# Taaghche-Sentiment-Analysis

This project implements a sentiment analysis model for Persian book reviews using PyTorch and the HuggingFace Transformers library. The model is trained on a dataset of book reviews from Taghche, a Persian e-book platform.
I added implemented a ğŸ‹ dockerfile for building a image.

![alt text](image.png)

## Table of Contents
- [Taaghche-Sentiment-Analysis](#taaghche-sentiment-analysis)
  - [Table of Contents](#table-of-contents)
  - [Overview](#overview)
  - [Requirements](#requirements)
  - [Dataset](#dataset)
  - [Preprocessing](#preprocessing)
  - [Model Architecture](#model-architecture)
  - [Data Flow](#data-flow)
  - [Training](#training)
  - [Results](#results)
  - [Usage](#usage)
  - [ğŸ‹ Docker Setup Guide for Taaghche Sentiment Analysis](#-docker-setup-guide-for-taaghche-sentiment-analysis)
    - [1. Building the Docker Image](#1-building-the-docker-image)
  - [Acknowledgments](#acknowledgments)

## Overview

This project aims to classify Persian book reviews into positive and negative sentiments. It uses a bidirectional LSTM model with an embedding layer and fully connected layers for classification. The model is trained on a balanced dataset of book reviews, where the sentiment is derived from the rating (1-5 stars) associated with each review.

I used the **HooshvareLab/bert-base-parsbert-uncased** tokenizer from Hugging Face's transformers library to tokenize and encode the Persian text into numeric representations that can be fed into the model.

## Requirements

- **Hazm** (for Persian text processing)
- **Transformers** (HuggingFace)
- PyTorch
- Scikit-learn
- tqdm

You can install the required packages using pip:

## Dataset

The dataset used in this project is a CSV file named 'taghche.csv', containing Persian book reviews. Each review includes the following information:
- Comment text
- Rating (1-5 stars)
- Date
- Book name
- Book ID
- Number of likes

|    Id | date       | comment                                                                                                                                                                                                                         | bookname           | rate | bookID | like |
| ----: | :--------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | :----------------- | ---: | -----: | ---: |
| 69824 | 1398/06/13 | Ù…Ù† Ú†Ø§Ù¾ÛŒØ´ Ø±Ùˆ Ø®ÙˆÙ†Ø¯Ù… Ø®ÛŒÙ„ÛŒ Ù‡Ù… Ù„Ø°Øª Ø¨Ø±Ø¯Ù….Ø¨Ù‡ Ù†Ø¸Ø±Ù… Ù…ÙˆØ¶ÙˆØ¹Ø´ ØªÚ©Ø±Ø§Ø±ÛŒ Ù†Ø¨ÙˆØ¯ Ùˆ Ø§Ø² Ø§ÛŒÙ† Ù„ÙˆØ³ Ø¨Ø§Ø²ÛŒÙ‡Ø§ÛŒ. Ø±Ù…Ø§Ù†ÛŒ Ù†Ø¯Ø§Ø´Øª.Ù‡Ø± Ú†Ù†Ø¯ Ù…Ø±Ú¯ Ø¯Ø®ØªØ±Ø´ Ø®ÛŒÙ„ÛŒ ØªÙ„Ø® Ø¨ÙˆØ¯ Ø§Ù…Ø§ Ø¯Ø± Ú©Ù„ Ø¹Ø§Ù„ÛŒ Ø¨ÙˆØ¯.Ú©Ø§Ø´ Ù†Ø´Ø± Ø³Ø®Ù† Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡ Ù‡Ø§ÛŒ Ø®ÙˆØ¨Ø´ Ø±Ùˆ Ø¨ÛŒØ´ØªØ± Ù…Ø¹Ø±ÙÛŒ Ù…ÛŒ Ú©Ø±Ø¯ ØªØ§ Ù…Ø±Ø¯Ù… Ù‡Ù… Ø¨ÛŒØ´ØªØ± Ø¢Ø´Ù†Ø§ Ø¨Ø´Ù† . | Ø±Ùˆ Ø¨Ù‡ Ø¨Ø§Ø¯          |    5 |  59636 |    3 |
| 69825 | 1398/06/16 | Ú©Ø§Ø´ ÛŒÙ‡ ØªØ®ÙÛŒÙ Ù…ÛŒØ°Ø§Ø´ØªÙ† . Ø®ÛŒÙ„ÛŒ Ø¯ÙˆØ³Øª Ø¯Ø§Ø±Ù… Ø¨Ø®ÙˆÙ†Ù…Ø´                                                                                                                                                                                    | ØªØ­Ù‚ÛŒØ± Ùˆ ØªÙˆÙ‡ÛŒÙ†â€ŒØ´Ø¯Ù‡â€ŒÙ‡Ø§ |    5 |  59638 |    2 |
| 69826 | 1398/05/26 | Ø§ÛŒÙ† Ú©ØªØ§Ø¨ Ø¯Ø§Ø³ØªØ§Ù† Ø¯Ø±Ø¯ Ùˆ Ø±Ù†Ø¬ Ú©Ø´Ø§ÙˆØ±Ø²Ø§Ù† Ø¨ÛŒÚ©Ø§Ø±Ø´Ø¯Ù‡â€ŒÛŒ Ø¢Ù…Ø±ÛŒÚ©Ø§ Ø¨Ù‡â€ŒØ¯Ù†Ø¨Ø§Ù„ Ø±Ø´Ø¯ ØµÙ†Ø¹ØªÛŒ Ø§Ø³ØªØŒ Ú©Ù‡ Ù‡Ù…â€ŒØ¯Ø§Ø³ØªØ§Ù†Ù ØªÙ…Ø§Ù… Ù…Ø±Ø¯Ù…Ø§Ù† ÙÙ‚ÛŒØ± Ùˆ Ø·Ø±Ø¯Ø´Ø¯Ù‡ Ø§Ø² Ø¬Ø§Ù…Ø¹Ù‡ Ù‡Ø³ØªÙ†Ø¯.                                                                                                | Ø®ÙˆØ´Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø´Ù…        |    5 |  59645 |    9 |
|       |            | Ø¯Ø§Ø³ØªØ§Ù† Ù‡Ù… Ø³ÙˆØ±Ù¾Ø±Ø§ÛŒØ² Ø®Ø§ØµÛŒ Ù†Ø¯Ø§Ø±Ù‡ØŒ ÙÙ‚Ø± Ùˆ ÙÙ„Ø§Ú©Øª Ø¯Ø§Ø³ØªØ§Ù† Ø¬Ø¯ÛŒØ¯ÛŒ Ù†ÛŒØ³ØªØŒ Ø§Ù…Ø§ Ø§ÛŒÙ† Ø¯ÙØ¹Ù‡ Ø¨Ø§ Ù‚Ù„Ù… Ù‡Ù†Ø±Ù…Ù†Ø¯Ø§Ù†Ù‡â€ŒÛŒ Ø¬Ø§Ù† Ø§Ø³ØªØ§ÛŒÙ†â€ŒØ¨Ú©Ù‡ØŒ Ú©Ù‡ Ø§Ø±Ø²Ø´ Ø®ÙˆÙ†Ø¯Ù† Ø¯Ø§Ø±Ù‡.                                                                                                 |                    |      |        |      |
| 69827 | 1398/09/29 | Ú©ØªØ§Ø¨ÛŒ ÙÙˆÙ‚ Ø§Ù„Ø¹Ø§Ø¯Ù‡ Ø²ÛŒØ¨Ø§ Ùˆ Ø¹Ø§Ù„ÛŒ                                                                                                                                                                                                    | Ù…ÙˆØ´â€ŒÙ‡Ø§ Ùˆ Ø¢Ø¯Ù…â€ŒÙ‡Ø§      |    5 |  59646 |    0 |
| 69828 | 1398/07/24 | ÛŒÚ©ÛŒ Ø§Ø² Ø¨Ù‡ØªØ±ÛŒÙ† Ùˆ ØªÙ„Ø® ØªØ±ÛŒÙ† Ø±Ù…Ø§Ù† Ù‡Ø§ÛŒ Ø¹Ù…Ø±Ù…!ÙˆØ§Ù‚Ø¹Ø§ Ø¯Ø±Ø¯Ø§ÙˆØ± Ùˆ Ø¯Ø±Ø¹ÛŒÙ† Ø­Ø§Ù„ Ø¨ÛŒ Ù†Ø¸ÛŒØ± Ø¨ÙˆØ¯.Ø§Ù„Ø¨ØªÙ‡ Ù…Ù† ØµÙˆØªÛŒØ´Ùˆ Ú¯ÙˆØ´ Ø¯Ø§Ø¯Ù….Ø´Ø§ÛŒØ¯ Ø¯Ø§Ø³ØªØ§Ù† Ø§Ø¯Ù… Ù‡Ø§ÛŒÛŒ Ø¨Ø§Ø´Ù‡ Ú©Ù‡ Ú©ÙˆØ¯Ú© Ø¯Ø±ÙˆÙ†Ø´ÙˆÙ† Ø±Ùˆ Ø¨Ø§ Ø¯Ø³ØªØ§ÛŒ Ø®ÙˆØ¯Ø´ÙˆÙ† Ù…ÛŒ Ú©Ø´Ù†...                                                     | Ù…ÙˆØ´â€ŒÙ‡Ø§ Ùˆ Ø¢Ø¯Ù…â€ŒÙ‡Ø§      |    5 |  59646 |    4 |

The dataset is preprocessed and balanced to ensure an equal distribution of positive and negative sentiments.

## Preprocessing

The preprocessing pipeline is implemented in multiple functions that clean and normalize the text data. Key steps include:

- Stopword Removal: I gathered 4 files of Persian stopwords that Filters them out from the text.
- Normalization: Applies character and affix spacing, Lemmatization and Stemming using **Hazm**
- Emoji, Links, and Special Character Removal: Cleans the text from non-informative elements such as emojis, links, and other special characters.

## Model Architecture

The model used is a Bidirectional LSTM-based Recurrent Neural Network (RNN) implemented in PyTorch. It processes tokenized sequences and applies multiple layers, including an embedding layer, LSTM, fully connected layers, and a final sigmoid activation to predict the sentiment.

1. **Embedding Layer**: Converts input tokens to dense vectors.

2. **Bidirectional LSTM**: Processes sequences, capturing context from both directions.

3. **Feature Extraction**: Concatenates final hidden states from both LSTM directions.

4. **Classification Head**:
   - First fully connected layer
   - Batch normalization
   - GELU activation
   - Second fully connected layer
   - Sigmoid activation

## Data Flow

1. Input â†’ Embedding â†’ Bidirectional LSTM
2. LSTM output â†’ Concatenation â†’ FC layers
3. FC output â†’ Batch Norm â†’ GELU â†’ FC â†’ Sigmoid
4. Final output: Single probability value (0-1)

This architecture efficiently handles variable-length sequences and is suitable for tasks like sentiment analysis or text classification.

## Training

The model is trained using:
- AdamW optimizer
- Binary Cross-Entropy loss
- ReduceLROnPlateau learning rate scheduler
- Batch size of 256
- Training for 100 epochs (or until convergence)

## Results

The final model achieves a test accuracy of **86.74%** on the held-out test set.

## Usage

To use this model for sentiment analysis:

1. Prepare your data in a similar format to the original dataset.
2. Run the preprocessing steps on your data.
3. Load the trained model:

```python
model = RNN(vocab_size, num_embd, rnn_hidden, fcl_hidden)
model.load_state_dict(torch.load('model_taghche.pth'))
model.eval()
```

4. Use the model to predict sentiment:

```python
def predict_sentiment(text):
    encoded = tokenizer.encode(text)
    input_tensor = torch.tensor(encoded).unsqueeze(0).to(device)
    lengths = torch.tensor([len(encoded)]).to(device)
    with torch.no_grad():
        output = model(input_tensor, lengths)
    return "Positive" if output.item() > 0.5 else "Negative"

sentiment = predict_sentiment("Ú©ØªØ§Ø¨ Ø¨Ø³ÛŒØ§Ø± Ø¨Ø¯ÛŒ Ø¨ÙˆØ¯. Ø§Ù‡ Ø§Ù‡")
print(f"Predicted sentiment: {sentiment}")
```

| Original Comment                                             | Preprocessed Comment                                   | Sentiment |
| ------------------------------------------------------------ | ------------------------------------------------------ | --------- |
| Ú©ØªØ§Ø¨ Ø¨Ø³ÛŒØ§Ø± Ø¨Ø¯ÛŒ Ø¨ÙˆØ¯. Ø§Ù‡ Ø§Ù‡                                    | Ú©ØªØ§Ø¨ Ø¨Ø¯ Ø§Ù‡ Ø§Ù‡                                          | Negative  |
| Ø®ÛŒÙ„ÛŒ Ù‚Ø´Ù†Ú¯ Ø¨ÙˆØ¯ Ø¨Ù†Ø¸Ø± Ú©ØªØ§Ø¨ Ø®ÙˆØ¨ÛŒ Ù…ÛŒÙˆÙ…Ø¯                           | Ø®ÛŒÙ„ Ù‚Ø´Ù†Ú¯ Ø¨ÙˆØ¯Ø§Ø³Øª Ø¨Ù†Ø¸Ø± Ú©ØªØ§Ø¨ Ø®ÙˆØ¨ Ù…ÛŒÙˆÙ…Ø¯                    | Positive  |
| Ø§ÙØªØ¶Ø§Ø­ ÙˆÙ‚ØªØªÙˆÙ† Ø±Ùˆ ØªÙ„Ù Ù†Ú©Ù†ÛŒØ¯                                   | Ø§ÙØªØ¶Ø§Ø­ ÙˆÙ‚ØªØªÙˆÙ† Ø±Ùˆ ØªÙ„Ù Ú©Ø±Ø¯Ú©Ù†                             | Negative  |
| ÙÚ©Ø± Ø²ÛŒØ¨Ø§ Ú©ØªØ§Ø¨ Ø¨ÙˆØ¯. Ù…Ø®ØµÙˆØµØ§ ØµØ¯Ø§ÛŒ Ø§Ø­Ù…Ø¯ Ø´Ø§Ù…Ù„Ùˆ Ø²ÛŒØ¨Ø§ Ú©ØªØ§Ø¨ Ø±Ùˆ Ù…ÛŒÚ©Ù†Ù‡ | ÙÚ©Ø± Ø²ÛŒØ¨Ø§ Ú©ØªØ§Ø¨ Ù…Ø®ØµÙˆØµØ§ ØµØ¯Ø§ Ø§Ø­Ù…Ø¯ Ø´Ø§Ù…Ù„Ùˆ Ø²ÛŒØ¨Ø§ Ú©ØªØ§Ø¨ Ø±Ùˆ Ù…ÛŒÚ©Ù†Ù‡ | Positive  |

---
## ğŸ‹ Docker Setup Guide for Taaghche Sentiment Analysis

### 1. Building the Docker Image

First, clone the repository if you havenâ€™t done so:

```bash
git clone https://github.com/your-username/Taaghche-Sentiment-Analysis.git
cd Taaghche-Sentiment-Analysis
```
To build the Docker image, run:

```bash
docker build -t taagche-sentiment .
```
open http://localhost:8001 to see the Site and UI

![alt text](image-1.png)


## Acknowledgments
- **Hazm Library**: Persian text processing tools.
- **HooshvareLab ParsBERT**: Tokenizer and language models for Persian.
- **Taghche Platform**: Providing the dataset of user comments.